{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = '/Applications/anaconda/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/opt/apache-spark/libexec\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "conf = (pyspark.SparkConf()\n",
    "    .setMaster('local')\n",
    "    .setAppName('pyspark')\n",
    "    .set(\"spark.executor.memory\", \"2g\"))\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.7.10 |Anaconda 2.4.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.4.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.4.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.4.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.4.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.4.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.4.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.4.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.4.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]',\n",
       " '2.7.10 |Anaconda 2.4.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "rdd = sc.parallelize(xrange(10),10)\n",
    "rdd.map(lambda x: sys.version).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.10 |Anaconda 2.4.0 (x86_64)| (default, Oct 19 2015, 18:31:17) \\n[GCC 4.2.1 (Apple Inc. build 5577)]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlsc=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2006-2015\n",
    "frames = []\n",
    "for i in range(1,344) : \n",
    "    dfs = pd.read_csv(\"2006-2015data/docsdf-\"+str(i)+\".csv\")\n",
    "    frames.append(dfs)\n",
    "df2015 = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1996-2005\n",
    "frames = []\n",
    "for i in range(344,704) : \n",
    "    dfs = pd.read_csv(\"1996-2005data/docsdf-\"+str(i)+\".csv\")\n",
    "    frames.append(dfs)\n",
    "df2005 = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1986-1995\n",
    "frames = []\n",
    "for i in range(704,1064) : \n",
    "    dfs = pd.read_csv(\"1986-1995data/docsdf-\"+str(i)+\".csv\")\n",
    "    frames.append(dfs)\n",
    "df1995 = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1976-1985\n",
    "frames = []\n",
    "for i in range(1064,1338) : \n",
    "    dfs = pd.read_csv(\"1976-1985data/docsdf-\"+str(i)+\".csv\")\n",
    "    frames.append(dfs)\n",
    "for i in range(1346,1424) : \n",
    "    dfs = pd.read_csv(\"1976-1985data/docsdf-\"+str(i)+\".csv\")\n",
    "    frames.append(dfs)\n",
    "df1985 = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1966-1975\n",
    "frames = []\n",
    "for i in range(1424,1784) : \n",
    "    dfs = pd.read_csv(\"1966-1975data/docsdf-\"+str(i)+\".csv\")\n",
    "    frames.append(dfs)\n",
    "df1975 = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine dfs together\n",
    "totalframes = [df2015,df2005,df1995,df1985,df1975]\n",
    "totaldf = pd.concat(totalframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totaldf.to_csv(\"total.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>id</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>section</th>\n",
       "      <th>subsection</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctype</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>369890</td>\n",
       "      <td>146721</td>\n",
       "      <td>369890</td>\n",
       "      <td>369890</td>\n",
       "      <td>369890</td>\n",
       "      <td>279836</td>\n",
       "      <td>351404</td>\n",
       "      <td>287169</td>\n",
       "      <td>39932</td>\n",
       "      <td>369890</td>\n",
       "      <td>369886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blogpost</th>\n",
       "      <td>31369</td>\n",
       "      <td>31364</td>\n",
       "      <td>31369</td>\n",
       "      <td>31369</td>\n",
       "      <td>31369</td>\n",
       "      <td>2854</td>\n",
       "      <td>18734</td>\n",
       "      <td>30313</td>\n",
       "      <td>6155</td>\n",
       "      <td>31369</td>\n",
       "      <td>31369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multimedia</th>\n",
       "      <td>1879</td>\n",
       "      <td>0</td>\n",
       "      <td>1879</td>\n",
       "      <td>1879</td>\n",
       "      <td>1879</td>\n",
       "      <td>1558</td>\n",
       "      <td>1873</td>\n",
       "      <td>1558</td>\n",
       "      <td>363</td>\n",
       "      <td>1879</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recipe</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0  abstract    date  headline      id  news_desk  paragraph  section  subsection    text    type\n",
       "doctype                                                                                                              \n",
       "article         369890    146721  369890    369890  369890     279836     351404   287169       39932  369890  369886\n",
       "blogpost         31369     31364   31369     31369   31369       2854      18734    30313        6155   31369   31369\n",
       "column              13        13      13        13      13          0         13       13           0      13      13\n",
       "multimedia        1879         0    1879      1879    1879       1558       1873     1558         363    1879    1560\n",
       "recipe             108         0     108       108     108          0         83        0           0     108     108"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totaldf.groupby('doctype').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#workding dataframe\n",
    "df = df1975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>date</th>\n",
       "      <th>doctype</th>\n",
       "      <th>headline</th>\n",
       "      <th>id</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>section</th>\n",
       "      <th>subsection</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1st article in series on NYC munic hosp system...</td>\n",
       "      <td>1975-01-05</td>\n",
       "      <td>article</td>\n",
       "      <td>City's Hospitals Agency Approaching Insolvency...</td>\n",
       "      <td>4fc494cb45c1498b0da6fe92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Five years after the city's Health and Hospita...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City's Hospitals Agency Approaching Insolvency...</td>\n",
       "      <td>Front Page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NYC Health and Hospitals Corp plans, for first...</td>\n",
       "      <td>1975-01-08</td>\n",
       "      <td>article</td>\n",
       "      <td>City Hospitals Set to Open Doors to Private Do...</td>\n",
       "      <td>4fc496e745c1498b0da79587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The city's Health and Hospitals Corporation pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City Hospitals Set to Open Doors to Private Do...</td>\n",
       "      <td>Article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ed notes adm and fiscal problems of NYCs munic...</td>\n",
       "      <td>1975-01-08</td>\n",
       "      <td>article</td>\n",
       "      <td>Sick Hospitals</td>\n",
       "      <td>4fc499f345c1498b0da85bd7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No chronic disease the city's municipal hospit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sick Hospitals No chronic disease the city's m...</td>\n",
       "      <td>Editorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975-01-05</td>\n",
       "      <td>article</td>\n",
       "      <td>National Health Insurance Debated</td>\n",
       "      <td>4fc48b6245c1498b0da47dea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON--Throughout this decade liberals on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Health Insurance Debated WASHINGTON--...</td>\n",
       "      <td>Article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Brit Sec of State of Soc Services Barbara Cast...</td>\n",
       "      <td>1975-01-09</td>\n",
       "      <td>article</td>\n",
       "      <td>Britain Settles Pay Dispute With 17,000 Hospit...</td>\n",
       "      <td>4fc48e3445c1498b0da531fe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LONDON, Jan. 8 (UPI)--More than 17,000 hospita...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Britain Settles Pay Dispute With 17,000 Hospit...</td>\n",
       "      <td>Article</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           abstract        date  doctype                                           headline                        id  news_desk                                          paragraph  section  subsection                                               text        type\n",
       "0           0  1st article in series on NYC munic hosp system...  1975-01-05  article  City's Hospitals Agency Approaching Insolvency...  4fc494cb45c1498b0da6fe92        NaN  Five years after the city's Health and Hospita...      NaN         NaN  City's Hospitals Agency Approaching Insolvency...  Front Page\n",
       "1           1  NYC Health and Hospitals Corp plans, for first...  1975-01-08  article  City Hospitals Set to Open Doors to Private Do...  4fc496e745c1498b0da79587        NaN  The city's Health and Hospitals Corporation pl...      NaN         NaN  City Hospitals Set to Open Doors to Private Do...     Article\n",
       "2           2  Ed notes adm and fiscal problems of NYCs munic...  1975-01-08  article                                     Sick Hospitals  4fc499f345c1498b0da85bd7        NaN  No chronic disease the city's municipal hospit...      NaN         NaN  Sick Hospitals No chronic disease the city's m...   Editorial\n",
       "3           3                                                NaN  1975-01-05  article                  National Health Insurance Debated  4fc48b6245c1498b0da47dea        NaN  WASHINGTON--Throughout this decade liberals on...      NaN         NaN  National Health Insurance Debated WASHINGTON--...     Article\n",
       "4           4  Brit Sec of State of Soc Services Barbara Cast...  1975-01-09  article  Britain Settles Pay Dispute With 17,000 Hospit...  4fc48e3445c1498b0da531fe        NaN  LONDON, Jan. 8 (UPI)--More than 17,000 hospita...      NaN         NaN  Britain Settles Pay Dispute With 17,000 Hospit...     Article"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50327, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['date'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mask = np.ones(len(df), dtype='int')\n",
    "#mask[df['date'].isnull()] = 0\n",
    "#mask = (mask == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_date = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_date.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "abstract       object\n",
       "date           object\n",
       "doctype        object\n",
       "headline       object\n",
       "id             object\n",
       "news_desk     float64\n",
       "paragraph      object\n",
       "section       float64\n",
       "subsection    float64\n",
       "text           object\n",
       "type           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             int64\n",
       "abstract              object\n",
       "date          datetime64[ns]\n",
       "doctype               object\n",
       "headline              object\n",
       "id                    object\n",
       "news_desk            float64\n",
       "paragraph             object\n",
       "section              float64\n",
       "subsection           float64\n",
       "text                  object\n",
       "type                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer #token\n",
    "from nltk.corpus import stopwords #stopwords\n",
    "from nltk.stem import WordNetLemmatizer #lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info http://www.nltk.org/nltk_data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "# blog post on # of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parts(thetext):\n",
    "    nouns=[]\n",
    "    tokens = TreebankWordTokenizer().tokenize(thetext)\n",
    "    tagged = nltk.pos_tag(tokens) # a list of tuples\n",
    "    for tup in tagged : \n",
    "        w, tag = tup  \n",
    "        print w, tag\n",
    "        if tag in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "            word = wnl.lemmatize(w.lower())\n",
    "            print word\n",
    "            if word[-1] in punctuation : \n",
    "                word = word[:-1]\n",
    "            if word in stops or word in punctuation or len(word)==1 :\n",
    "                continue\n",
    "            nouns.append(word)\n",
    "    nouns2=[]\n",
    "    for n in nouns:\n",
    "        if len(n)!=0:\n",
    "            nouns2.append(n)\n",
    "    return nouns2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')\n",
    "stops.append(u'health')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punctuation = list('.,;:!?()[]{}`''\\\"@#$^&*+-|=~_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource u'taggers/averaged_perceptron_tagger/averaged_perceptro\n  n_tagger.pickle' not found.  Please use the NLTK Downloader to\n  obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/Users/yandong/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2c501a995d16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A New, Life-or-Death. Approach. to Funding Heart Research.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-124314dc44d3>\u001b[0m in \u001b[0;36mget_parts\u001b[0;34m(thetext)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnouns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreebankWordTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# a list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtagged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagged\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/nltk/tag/__init__.pyc\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/nltk/tag/perceptron.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource u'taggers/averaged_perceptron_tagger/averaged_perceptro\n  n_tagger.pickle' not found.  Please use the NLTK Downloader to\n  obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/Users/yandong/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "get_parts(\"A New, Life-or-Death. Approach. to Funding Heart Research.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####test####\n",
    "a = TreebankWordTokenizer().tokenize(\"A New, Life-or-Death. Approach. to Funding Heart Research.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource u'taggers/averaged_perceptron_tagger/averaged_perceptro\n  n_tagger.pickle' not found.  Please use the NLTK Downloader to\n  obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/Users/yandong/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0af9a577e0f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/nltk/tag/__init__.pyc\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/nltk/tag/perceptron.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource u'taggers/averaged_perceptron_tagger/averaged_perceptro\n  n_tagger.pickle' not found.  Please use the NLTK Downloader to\n  obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/Users/yandong/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "#####test#####\n",
    "t = nltk.pos_tag(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5 method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.en import parse\n",
    "from pattern.en import pprint\n",
    "from pattern.vector import stem, PORTER, LEMMA\n",
    "punctuation = list('.,;:!?()[]{}`''\\\"@#$^&*+-|=~_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "stopwords=text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex1=re.compile(r\"\\.{2,}\")\n",
    "regex2=re.compile(r\"\\-{2,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parts(thetext):\n",
    "    thetext=re.sub(regex1, ' ', thetext)\n",
    "    thetext=re.sub(regex2, ' ', thetext)\n",
    "    nouns=[]\n",
    "    for i,sentence in enumerate(parse(thetext, tokenize=True, lemmata=True).split()):\n",
    "        nouns.append([])\n",
    "        for token in sentence:\n",
    "            if len(token[4]) >0:\n",
    "                if token[1] in ['NN', 'NNS', 'NNP']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    nouns[i].append(token[4])\n",
    "    nouns2=[]\n",
    "    for n in nouns:\n",
    "        if len(n)!=0:\n",
    "            nouns2.append(n)\n",
    "    return nouns2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 21s, sys: 2.56 s, total: 7min 24s\n",
      "Wall time: 7min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parseout = []\n",
    "for index, row in df.iterrows() : \n",
    "    parseout.append(get_parts(row.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[u'city',\n",
       "   u'hospitals',\n",
       "   u'agency',\n",
       "   u'insolvency',\n",
       "   u'hospital',\n",
       "   u'unit',\n",
       "   u'insolvency',\n",
       "   u'year',\n",
       "   u'city',\n",
       "   u'health',\n",
       "   u'hospitals',\n",
       "   u'corporation',\n",
       "   u'quality',\n",
       "   u'care',\n",
       "   u'hospital',\n",
       "   u'patient',\n",
       "   u'treatment',\n",
       "   u'corporation',\n",
       "   u'article',\n",
       "   u'series',\n",
       "   u'nyc',\n",
       "   u'hosp',\n",
       "   u'nyc',\n",
       "   u'health',\n",
       "   u'hosps',\n",
       "   u'corp',\n",
       "   u'quality',\n",
       "   u'care',\n",
       "   u'hosps',\n",
       "   u'treatment',\n",
       "   u'minimum',\n",
       "   u'health',\n",
       "   u'care',\n",
       "   u'lack',\n",
       "   u'service',\n",
       "   u'coney',\n",
       "   u'island',\n",
       "   u'harlem',\n",
       "   u'lincoln',\n",
       "   u'city',\n",
       "   u'hosp',\n",
       "   u'center',\n",
       "   u'elmhurst',\n",
       "   u'portrait',\n",
       "   u'hosp']],\n",
       " [[u'city',\n",
       "   u'hospitals',\n",
       "   u'door',\n",
       "   u'doctor',\n",
       "   u'city',\n",
       "   u'health',\n",
       "   u'hospitals',\n",
       "   u'corporation',\n",
       "   u'time',\n",
       "   u'doctor',\n",
       "   u'patient',\n",
       "   u'city',\n",
       "   u'hospital',\n",
       "   u'hospital',\n",
       "   u'facility',\n",
       "   u'practice',\n",
       "   u'effort',\n",
       "   u'money',\n",
       "   u'talent'],\n",
       "  [u'nyc',\n",
       "   u'health',\n",
       "   u'corp',\n",
       "   u'time',\n",
       "   u'drs',\n",
       "   u'patient',\n",
       "   u'city',\n",
       "   u'hosps',\n",
       "   u'facility',\n",
       "   u'practice',\n",
       "   u'effort',\n",
       "   u'money',\n",
       "   u'talent',\n",
       "   u'ailing',\n",
       "   u'corp',\n",
       "   u'dr',\n",
       "   u'john',\n",
       "   u'holloman',\n",
       "   u'step',\n",
       "   u'fund',\n",
       "   u'pub',\n",
       "   u'hosps',\n",
       "   u'patient',\n",
       "   u'hospitalization',\n",
       "   u'plan',\n",
       "   u'blue',\n",
       "   u'cross',\n",
       "   u'drs',\n",
       "   u'patient',\n",
       "   u'occupancy',\n",
       "   u'rate',\n",
       "   u'hosps',\n",
       "   u'talent',\n",
       "   u'holloman',\n",
       "   u'goal',\n",
       "   u'patient',\n",
       "   u'city',\n",
       "   u'hosps',\n",
       "   u'dr',\n",
       "   u'implementation',\n",
       "   u'plan',\n",
       "   u'month',\n",
       "   u'task',\n",
       "   u'force',\n",
       "   u'work',\n",
       "   u'problem',\n",
       "   u'drs',\n",
       "   u'creation',\n",
       "   u'century',\n",
       "   u'drs',\n",
       "   u'practice',\n",
       "   u'wall']],\n",
       " [[u'sick', u'hospitals', u'disease', u'city', u'hospital', u'problem'],\n",
       "  [u'study', u'reorganization', u'reform', u'way', u'laxity', u'inefficiency'],\n",
       "  [u'ed',\n",
       "   u'problem',\n",
       "   u'nycs',\n",
       "   u'hosps',\n",
       "   u'concern',\n",
       "   u'problem',\n",
       "   u'suffering',\n",
       "   u'ward',\n",
       "   u'need',\n",
       "   u'hosps',\n",
       "   u'center',\n",
       "   u'neighborhood',\n",
       "   u'health-care',\n",
       "   u'facility',\n",
       "   u'need',\n",
       "   u'natl',\n",
       "   u'approach',\n",
       "   u'health',\n",
       "   u'care']]]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parseout[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use entire document other than sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "document = [list(itertools.chain.from_iterable(p)) for p in parseout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'city',\n",
       "  u'hospitals',\n",
       "  u'agency',\n",
       "  u'insolvency',\n",
       "  u'hospital',\n",
       "  u'unit',\n",
       "  u'insolvency',\n",
       "  u'year',\n",
       "  u'city',\n",
       "  u'health',\n",
       "  u'hospitals',\n",
       "  u'corporation',\n",
       "  u'quality',\n",
       "  u'care',\n",
       "  u'hospital',\n",
       "  u'patient',\n",
       "  u'treatment',\n",
       "  u'corporation',\n",
       "  u'article',\n",
       "  u'series',\n",
       "  u'nyc',\n",
       "  u'hosp',\n",
       "  u'nyc',\n",
       "  u'health',\n",
       "  u'hosps',\n",
       "  u'corp',\n",
       "  u'quality',\n",
       "  u'care',\n",
       "  u'hosps',\n",
       "  u'treatment',\n",
       "  u'minimum',\n",
       "  u'health',\n",
       "  u'care',\n",
       "  u'lack',\n",
       "  u'service',\n",
       "  u'coney',\n",
       "  u'island',\n",
       "  u'harlem',\n",
       "  u'lincoln',\n",
       "  u'city',\n",
       "  u'hosp',\n",
       "  u'center',\n",
       "  u'elmhurst',\n",
       "  u'portrait',\n",
       "  u'hosp'],\n",
       " [u'city',\n",
       "  u'hospitals',\n",
       "  u'door',\n",
       "  u'doctor',\n",
       "  u'city',\n",
       "  u'health',\n",
       "  u'hospitals',\n",
       "  u'corporation',\n",
       "  u'time',\n",
       "  u'doctor',\n",
       "  u'patient',\n",
       "  u'city',\n",
       "  u'hospital',\n",
       "  u'hospital',\n",
       "  u'facility',\n",
       "  u'practice',\n",
       "  u'effort',\n",
       "  u'money',\n",
       "  u'talent',\n",
       "  u'nyc',\n",
       "  u'health',\n",
       "  u'corp',\n",
       "  u'time',\n",
       "  u'drs',\n",
       "  u'patient',\n",
       "  u'city',\n",
       "  u'hosps',\n",
       "  u'facility',\n",
       "  u'practice',\n",
       "  u'effort',\n",
       "  u'money',\n",
       "  u'talent',\n",
       "  u'ailing',\n",
       "  u'corp',\n",
       "  u'dr',\n",
       "  u'john',\n",
       "  u'holloman',\n",
       "  u'step',\n",
       "  u'fund',\n",
       "  u'pub',\n",
       "  u'hosps',\n",
       "  u'patient',\n",
       "  u'hospitalization',\n",
       "  u'plan',\n",
       "  u'blue',\n",
       "  u'cross',\n",
       "  u'drs',\n",
       "  u'patient',\n",
       "  u'occupancy',\n",
       "  u'rate',\n",
       "  u'hosps',\n",
       "  u'talent',\n",
       "  u'holloman',\n",
       "  u'goal',\n",
       "  u'patient',\n",
       "  u'city',\n",
       "  u'hosps',\n",
       "  u'dr',\n",
       "  u'implementation',\n",
       "  u'plan',\n",
       "  u'month',\n",
       "  u'task',\n",
       "  u'force',\n",
       "  u'work',\n",
       "  u'problem',\n",
       "  u'drs',\n",
       "  u'creation',\n",
       "  u'century',\n",
       "  u'drs',\n",
       "  u'practice',\n",
       "  u'wall'],\n",
       " [u'sick',\n",
       "  u'hospitals',\n",
       "  u'disease',\n",
       "  u'city',\n",
       "  u'hospital',\n",
       "  u'problem',\n",
       "  u'study',\n",
       "  u'reorganization',\n",
       "  u'reform',\n",
       "  u'way',\n",
       "  u'laxity',\n",
       "  u'inefficiency',\n",
       "  u'ed',\n",
       "  u'problem',\n",
       "  u'nycs',\n",
       "  u'hosps',\n",
       "  u'concern',\n",
       "  u'problem',\n",
       "  u'suffering',\n",
       "  u'ward',\n",
       "  u'need',\n",
       "  u'hosps',\n",
       "  u'center',\n",
       "  u'neighborhood',\n",
       "  u'health-care',\n",
       "  u'facility',\n",
       "  u'need',\n",
       "  u'natl',\n",
       "  u'approach',\n",
       "  u'health',\n",
       "  u'care'],\n",
       " [u'national',\n",
       "  u'health',\n",
       "  u'insurance',\n",
       "  u'debated',\n",
       "  u'decade',\n",
       "  u'liberal',\n",
       "  u'capitol',\n",
       "  u'hill',\n",
       "  u'health',\n",
       "  u'insurance',\n",
       "  u'issue',\n",
       "  u'time'],\n",
       " [u'britain',\n",
       "  u'settles',\n",
       "  u'pay',\n",
       "  u'dispute',\n",
       "  u'hospital',\n",
       "  u'doctor',\n",
       "  u'jan',\n",
       "  u'upi',\n",
       "  u'hospital',\n",
       "  u'doctor',\n",
       "  u'pay',\n",
       "  u'dispute',\n",
       "  u'government',\n",
       "  u'today',\n",
       "  u'slowdown',\n",
       "  u'britain',\n",
       "  u'national',\n",
       "  u'health',\n",
       "  u'service',\n",
       "  u'brit',\n",
       "  u'sec',\n",
       "  u'state',\n",
       "  u'soc',\n",
       "  u'services',\n",
       "  u'barbara',\n",
       "  u'castle',\n",
       "  u'reprs',\n",
       "  u'drs',\n",
       "  u'drs',\n",
       "  u'rate',\n",
       "  u'work',\n",
       "  u'wk',\n",
       "  u'drs',\n",
       "  u'hr',\n",
       "  u'overtime',\n",
       "  u'resident',\n",
       "  u'drs',\n",
       "  u'slowdown']]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldadatardd=sc.parallelize([document]).flatMap(lambda l: l)\n",
    "ldadatardd.cache()\n",
    "ldadatardd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#using sentences\n",
    "#ldadatardd=sc.parallelize(parseout).flatMap(lambda l: l)\n",
    "#ldadatardd.cache()\n",
    "#ldadatardd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creat word vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabtups = (ldadatardd.flatMap(lambda word: word)\n",
    "             .map(lambda word: (word, 1))\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "             .map(lambda (x,y): x)\n",
    "             .zipWithIndex()\n",
    ").cache()\n",
    "############store the count of words##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'fawn', 0),\n",
       " (u'cat-and-dog', 1),\n",
       " (u'cyclophophamide', 2),\n",
       " (u'schlegel', 3),\n",
       " (u'leaded-gas', 4)]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabtups.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=vocabtups.collectAsMap()\n",
    "id2word=vocabtups.map(lambda (x,y): (y,x)).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58520"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'A/DT/B-NP/O/a New/NNP/I-NP/O/new ,/,/O/O/, Life-or-Death/NNP/B-NP/O/life-or-death Approach/NNP/I-NP/O/approach to/TO/O/O/to Funding/NNP/B-NP/O/funding Heart/NNP/I-NP/O/heart Research/NNP/I-NP/O/research'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####test####\n",
    "parse(\"A New, Life-or-Death Approach to Funding Heart Research\", tokenize=True, lemmata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_count(s) : \n",
    "    d = defaultdict(int)\n",
    "    for w in s : \n",
    "        if vocab.has_key(w) :\n",
    "            i = vocab[w]\n",
    "            d[i] += 1\n",
    "    return d.items()\n",
    "documents = ldadatardd.map(get_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(6913, 1),\n",
       "  (1672, 1),\n",
       "  (32779, 1),\n",
       "  (23180, 1),\n",
       "  (19469, 2),\n",
       "  (39823, 1),\n",
       "  (50194, 2),\n",
       "  (13972, 1),\n",
       "  (34137, 2),\n",
       "  (35488, 1),\n",
       "  (24865, 1),\n",
       "  (52515, 2),\n",
       "  (43435, 1),\n",
       "  (56584, 1),\n",
       "  (33586, 3),\n",
       "  (4796, 1),\n",
       "  (9021, 1),\n",
       "  (967, 1),\n",
       "  (26701, 2),\n",
       "  (36823, 1),\n",
       "  (48728, 2),\n",
       "  (10585, 2),\n",
       "  (27226, 3),\n",
       "  (54502, 3),\n",
       "  (361, 1),\n",
       "  (29933, 3),\n",
       "  (20849, 2),\n",
       "  (19322, 1),\n",
       "  (46717, 1)],\n",
       " [(27009, 1),\n",
       "  (5381, 1),\n",
       "  (34954, 1),\n",
       "  (32779, 2),\n",
       "  (16653, 1),\n",
       "  (4173, 1),\n",
       "  (14573, 1),\n",
       "  (28432, 1),\n",
       "  (29458, 2),\n",
       "  (32789, 1),\n",
       "  (34137, 2),\n",
       "  (20000, 1),\n",
       "  (22562, 2),\n",
       "  (52515, 2),\n",
       "  (18342, 2),\n",
       "  (54058, 2),\n",
       "  (9159, 2),\n",
       "  (41673, 1),\n",
       "  (10681, 1),\n",
       "  (45531, 1),\n",
       "  (20416, 1),\n",
       "  (51910, 1),\n",
       "  (967, 5),\n",
       "  (36041, 1),\n",
       "  (26701, 4),\n",
       "  (37583, 2),\n",
       "  (3491, 1),\n",
       "  (3927, 1),\n",
       "  (10585, 1),\n",
       "  (27226, 2),\n",
       "  (16475, 2),\n",
       "  (9488, 1),\n",
       "  (9443, 1),\n",
       "  (57834, 3),\n",
       "  (9835, 3),\n",
       "  (29933, 5),\n",
       "  (20849, 1),\n",
       "  (52467, 2),\n",
       "  (51832, 1),\n",
       "  (36090, 4),\n",
       "  (1917, 1)],\n",
       " [(31239, 1),\n",
       "  (52515, 1),\n",
       "  (17035, 1),\n",
       "  (10258, 1),\n",
       "  (21275, 1),\n",
       "  (24865, 1),\n",
       "  (3491, 3),\n",
       "  (10182, 1),\n",
       "  (33905, 1),\n",
       "  (36142, 1),\n",
       "  (15153, 1),\n",
       "  (33586, 1),\n",
       "  (17975, 1),\n",
       "  (29458, 1),\n",
       "  (52806, 1),\n",
       "  (26701, 2),\n",
       "  (40142, 1),\n",
       "  (50257, 2),\n",
       "  (31187, 1),\n",
       "  (34137, 1),\n",
       "  (27226, 1),\n",
       "  (19293, 1),\n",
       "  (50782, 1),\n",
       "  (29933, 1),\n",
       "  (48241, 1),\n",
       "  (33141, 1),\n",
       "  (19067, 1)],\n",
       " [(29345, 1),\n",
       "  (27106, 1),\n",
       "  (24715, 1),\n",
       "  (12709, 1),\n",
       "  (34490, 1),\n",
       "  (54058, 1),\n",
       "  (15115, 1),\n",
       "  (31875, 1),\n",
       "  (27226, 2),\n",
       "  (26906, 2)],\n",
       " [(27009, 1),\n",
       "  (46723, 2),\n",
       "  (32137, 1),\n",
       "  (11658, 1),\n",
       "  (24715, 1),\n",
       "  (29455, 1),\n",
       "  (21522, 1),\n",
       "  (26771, 1),\n",
       "  (30743, 2),\n",
       "  (52515, 2),\n",
       "  (28596, 1),\n",
       "  (47285, 1),\n",
       "  (16567, 1),\n",
       "  (4922, 2),\n",
       "  (9275, 1),\n",
       "  (21399, 1),\n",
       "  (35157, 1),\n",
       "  (18903, 1),\n",
       "  (32856, 1),\n",
       "  (27226, 1),\n",
       "  (50402, 1),\n",
       "  (12006, 1),\n",
       "  (49894, 1),\n",
       "  (361, 1),\n",
       "  (52467, 2),\n",
       "  (52469, 2),\n",
       "  (51832, 1),\n",
       "  (21204, 1),\n",
       "  (36090, 4)]]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus=documents.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lda2015 = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=50, update_every=1, chunksize=10000, passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "#lda2005 = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=50, update_every=1, chunksize=5000, passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lda1995 = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=50, update_every=1, chunksize=5000, passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lda1985 = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=50, update_every=1, chunksize=5000, passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda1975 = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=50, update_every=1, chunksize=5000, passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.066*school + 0.033*student + 0.029*program + 0.025*educ + 0.023*education + 0.018*teacher + 0.015*training + 0.009*schools + 0.008*college + 0.008*class',\n",
       " u'0.017*cabinet + 0.015*nation + 0.013*world + 0.012*year + 0.012*article + 0.010*regime + 0.009*illus + 0.008*problem + 0.008*econ + 0.008*min',\n",
       " u'0.055*treasury + 0.029*statement + 0.021*president + 0.020*company + 0.016*conference + 0.016*sale + 0.015*house + 0.015*ford + 0.015*corporation + 0.015*driver',\n",
       " u'0.057*home + 0.045*medicaid + 0.024*nursing + 0.021*fee + 0.020*investigation + 0.020*procaccino + 0.020*addict + 0.019*state + 0.015*abus + 0.015*probe',\n",
       " u'0.071*francis + 0.038*gardner + 0.035*donor + 0.033*costello + 0.013*ottawa + 0.011*savings + 0.010*group + 0.008*editorial + 0.008*citizen + 0.008*consol',\n",
       " u'0.046*safety + 0.043*agency + 0.018*ad + 0.015*pub + 0.014*advertising + 0.014*health + 0.012*federal + 0.012*standard + 0.011*today + 0.010*bureau',\n",
       " u'0.045*research + 0.043*drug + 0.025*food + 0.024*cancer + 0.023*study + 0.019*scientist + 0.016*natl + 0.015*use + 0.013*health + 0.012*dec',\n",
       " u'0.041*brown + 0.017*line + 0.015*demonstration + 0.015*coin + 0.015*boycott + 0.013*reagan + 0.012*page + 0.011*peddler + 0.011*little + 0.011*blast',\n",
       " u'0.046*security + 0.029*medicare + 0.027*social + 0.026*prison + 0.021*ball + 0.018*prisoner + 0.014*charge + 0.012*utah + 0.012*resolution + 0.011*diversion',\n",
       " u'0.058*cigarette + 0.035*smoking + 0.022*health + 0.019*smoker + 0.014*warning + 0.014*ad + 0.013*tobacco + 0.012*cont + 0.009*nicotine + 0.009*surgeon']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda1975.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
