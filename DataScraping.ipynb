{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "#import seaborn as sns\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Code: 1960s -past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 84\n",
      "2019 168\n",
      "2020 254\n",
      "2021 331\n",
      "2022 412\n",
      "2023 480\n",
      "Wall time: 12min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 2018 #enter new count starting number\n",
    "year = '1956' #enter year\n",
    "startmonths = ['01', '03', '05', '07', '09', '11']\n",
    "endmonths = ['02', '04', '06', '08', '10', '12']\n",
    "startdays = ['01', '01', '01', '01', '01', '01']\n",
    "enddays = ['27', '30', '30', '31', '31', '31']\n",
    "\n",
    "pcount = 0\n",
    "\n",
    "for d in range(6):\n",
    "    sdate = year + startmonths[d] + startdays[d]\n",
    "    edate = year + endmonths[d] + enddays[d]\n",
    "\n",
    "    docs=[]\n",
    "    #get 1st page and number of documents\n",
    "    url1 = \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=Health&page=1&begin_date={}&end_date={}&api-key=5cdab36b05348a4da2e74046dfb16a03:17:73541790\".format(sdate, edate) \n",
    "    lpage = requests.get(url1).json()['response']['meta']['hits']\n",
    "    \n",
    "    #calculate number of pages for call; if there are no hits skip to end\n",
    "    if lpage is not 0:\n",
    "        numpages = int(lpage/10 + 2) \n",
    "        pcount += numpages\n",
    "    \n",
    "        #get json files for first page\n",
    "        pagedoc1 = requests.get(url1).json()['response']['docs']\n",
    "        for j in range(0,len(pagedoc1)):\n",
    "            docs.append(pagedoc1[j])    \n",
    "    \n",
    "        #get json dictionaries for rest of the pages\n",
    "        for i in range(2, numpages): \n",
    "            url = \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=Health&page={}&begin_date={}&end_date={}&api-key=5cdab36b05348a4da2e74046dfb16a03:17:73541790\".format(i, sdate, edate)\n",
    "            pagedocs = requests.get(url).json()['response']['docs']\n",
    "            time.sleep(1)\n",
    "        \n",
    "            for j in range(0,len(pagedocs)):\n",
    "                docs.append(pagedocs[j])\n",
    "\n",
    "    #pull information from json file into dictionary        \n",
    "        docsinfo = []\n",
    "        for d in docs:\n",
    "            obs = {}\n",
    "            obs['id'] = d['_id']\n",
    "            obs['type'] = d['type_of_material']\n",
    "            obs['doctype'] = d['document_type']\n",
    "            obs['date'] = d['pub_date']\n",
    "            obs['news_desk'] = d['news_desk']\n",
    "            obs['section'] = d['section_name']\n",
    "            obs['subsection'] = d['subsection_name']\n",
    "            obs['abstract'] = d['abstract']\n",
    "            obs['paragraph'] = d['lead_paragraph']\n",
    "        \n",
    "            if d['headline'].get('main') is not None:\n",
    "                obs['headline'] = d['headline']['main']\n",
    "            elif d['headline'].get('name') is not None:\n",
    "                obs['headline'] = d['headline']['name']\n",
    "            else:\n",
    "                obs['headline'] = ' '\n",
    "    \n",
    "            if obs['date'] is not None:\n",
    "                obs['date'] = obs['date'][0:10]\n",
    "    \n",
    "            #Take out abstracts and lead paragraphs with none to join text\n",
    "            if obs['abstract'] is None:\n",
    "                a = ' '\n",
    "            else: \n",
    "                a = obs['abstract']\n",
    "            if obs['paragraph'] == 'TK TK TK' or obs['paragraph'] is None:\n",
    "                p = ' '\n",
    "            else:\n",
    "                p = obs['paragraph']\n",
    "    \n",
    "            text = [obs['headline'], p, a]\n",
    "            obs['text'] = \" \".join(text)\n",
    "    \n",
    "            docsinfo.append(obs)\n",
    "\n",
    "    #create dataframe from dictionary, make date column date type, and store in csv\n",
    "        docsdf = pd.DataFrame(docsinfo)\n",
    "        docsdf['date'] = pd.to_datetime(docsdf['date'])\n",
    "        docsdf.to_csv(\"data/docsdf-{}.csv\".format(count), encoding = 'utf-8') \n",
    "\n",
    "    print(count, pcount) \n",
    "    count += 1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "docs=[]\n",
    "ns = 1 #number of pages\n",
    "\n",
    "#get first 100 pages of json dictionaries\n",
    "for i in range(1,101): \n",
    "    url = \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=Health&page=%d&begin_date=20121211&end_date=20121220&api-key=5cdab36b05348a4da2e74046dfb16a03:17:73541790\" % i\n",
    "    page = requests.get(url)\n",
    "    pagedocs = page.json()['response']['docs']\n",
    "    time.sleep(1)\n",
    "    \n",
    "    #append each separate dictionary from a page to docs\n",
    "    for j in range(0,len(pagedocs)):\n",
    "        docs.append(pagedocs[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fd=open(\"data/nytdocs-19.json\",\"w\")\n",
    "json.dump(docs, fd)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docsinfo = []\n",
    "for d in docs:\n",
    "    obs = {}\n",
    "    obs['id'] = d['_id']\n",
    "    obs['type'] = d['type_of_material']\n",
    "    obs['doctype'] = d['document_type']\n",
    "    obs['date'] = d['pub_date']\n",
    "    obs['news_desk'] = d['news_desk']\n",
    "    obs['section'] = d['section_name']\n",
    "    obs['subsection'] = d['subsection_name']\n",
    "    obs['abstract'] = d['abstract']\n",
    "    obs['paragraph'] = d['lead_paragraph']\n",
    "    \n",
    "    if d['headline'].get('main') is not None:\n",
    "        obs['headline'] = d['headline']['main']\n",
    "    elif d['headline'].get('name') is not None:\n",
    "        obs['headline'] = d['headline']['name']\n",
    "    else:\n",
    "        obs['headline'] = ' '\n",
    "    \n",
    "    if obs['date'] is not None:\n",
    "        obs['date'] = obs['date'][0:10]\n",
    "    \n",
    "    #Take out abstracts and lead paragraphs with none to join text\n",
    "    if obs['abstract'] is None:\n",
    "        a = ' '\n",
    "    else: \n",
    "        a = obs['abstract']\n",
    "    if obs['paragraph'] == 'TK TK TK' or obs['paragraph'] is None:\n",
    "        p = ' '\n",
    "    else:\n",
    "        p = obs['paragraph']\n",
    "    \n",
    "    text = [obs['headline'], p, a]\n",
    "    obs['text'] = \" \".join(text)\n",
    "    \n",
    "    docsinfo.append(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsdf = pd.DataFrame(docsinfo)\n",
    "docsdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docsdf['date'] = pd.to_datetime(docsdf['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docsdf.to_csv(\"data/docsdf-814.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1964 17\n",
      "1965 32\n",
      "1966 46\n",
      "1967 58\n",
      "1968 71\n",
      "1969 81\n",
      "1970 92\n",
      "1971 105\n",
      "1972 121\n",
      "1973 138\n",
      "1974 149\n",
      "1975 162\n",
      "1976 177\n",
      "1977 192\n",
      "1978 205\n",
      "1979 221\n",
      "1980 237\n",
      "1981 249\n",
      "1982 263\n",
      "1983 276\n",
      "1984 293\n",
      "1985 305\n",
      "1986 316\n",
      "1987 333\n",
      "1988 346\n",
      "1989 359\n",
      "1990 370\n",
      "1991 382\n",
      "1992 393\n",
      "1993 408\n",
      "1994 422\n",
      "1995 437\n",
      "1996 448\n",
      "1997 460\n",
      "1998 474\n",
      "1999 485\n",
      "Wall time: 11min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count = 1964 #enter new count starting number\n",
    "year = '1960' #enter year\n",
    "months = ['01', '01', '01', '02', '02', '02', '03', '03', '03', '04', '04', '04', '05', '05', '05', '06', '06', '06', '07', '07', '07', '08', '08', '08', '09', '09', '09', '10', '10', '10', '11', '11', '11', '12', '12', '12']\n",
    "startdays = ['01', '11', '21', '01', '11', '21', '01', '11', '21', '01', '11', '21', '01', '11', '21', '01', '11', '21', '01', '11', '21', '01', '11', '21', '01', '11', '21', '01', '11', '21', '01', '11', '21', '01', '11', '21']\n",
    "enddays = ['10', '20', '31', '10', '20', '27', '10', '20', '31', '10', '20', '30', '10', '20', '31', '10', '20', '30', '10', '20', '31', '10', '20', '31', '10', '20', '30', '10', '20', '31', '10', '20', '30', '10', '20', '31']\n",
    "\n",
    "pcount = 0\n",
    "\n",
    "for d in range(36):\n",
    "    sdate = year + months[d] + startdays[d]\n",
    "    edate = year + months[d] + enddays[d]\n",
    "\n",
    "    docs=[]\n",
    "    #get 1st page and number of documents\n",
    "    url1 = \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=Health&page=1&begin_date={}&end_date={}&api-key=5cdab36b05348a4da2e74046dfb16a03:17:73541790\".format(sdate, edate) \n",
    "    lpage = requests.get(url1).json()['response']['meta']['hits']\n",
    "    \n",
    "    #calculate number of pages for call; if there are no hits skip to end\n",
    "    if lpage is not 0:\n",
    "        numpages = int(lpage/10 + 2) \n",
    "        pcount += numpages\n",
    "    \n",
    "        #get json files for first page\n",
    "        pagedoc1 = requests.get(url1).json()['response']['docs']\n",
    "        for j in range(0,len(pagedoc1)):\n",
    "            docs.append(pagedoc1[j])    \n",
    "    \n",
    "        #get json dictionaries for rest of the pages\n",
    "        for i in range(2, numpages): \n",
    "            url = \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=Health&page={}&begin_date={}&end_date={}&api-key=5cdab36b05348a4da2e74046dfb16a03:17:73541790\".format(i, sdate, edate)\n",
    "            pagedocs = requests.get(url).json()['response']['docs']\n",
    "            time.sleep(1)\n",
    "        \n",
    "            for j in range(0,len(pagedocs)):\n",
    "                docs.append(pagedocs[j])\n",
    "\n",
    "    #pull information from json file into dictionary        \n",
    "        docsinfo = []\n",
    "        for d in docs:\n",
    "            obs = {}\n",
    "            obs['id'] = d['_id']\n",
    "            obs['type'] = d['type_of_material']\n",
    "            obs['doctype'] = d['document_type']\n",
    "            obs['date'] = d['pub_date']\n",
    "            obs['news_desk'] = d['news_desk']\n",
    "            obs['section'] = d['section_name']\n",
    "            obs['subsection'] = d['subsection_name']\n",
    "            obs['abstract'] = d['abstract']\n",
    "            obs['paragraph'] = d['lead_paragraph']\n",
    "        \n",
    "            if d['headline'].get('main') is not None:\n",
    "                obs['headline'] = d['headline']['main']\n",
    "            elif d['headline'].get('name') is not None:\n",
    "                obs['headline'] = d['headline']['name']\n",
    "            else:\n",
    "                obs['headline'] = ' '\n",
    "    \n",
    "            if obs['date'] is not None:\n",
    "                obs['date'] = obs['date'][0:10]\n",
    "    \n",
    "            #Take out abstracts and lead paragraphs with none to join text\n",
    "            if obs['abstract'] is None:\n",
    "                a = ' '\n",
    "            else: \n",
    "                a = obs['abstract']\n",
    "            if obs['paragraph'] == 'TK TK TK' or obs['paragraph'] is None:\n",
    "                p = ' '\n",
    "            else:\n",
    "                p = obs['paragraph']\n",
    "    \n",
    "            text = [obs['headline'], p, a]\n",
    "            obs['text'] = \" \".join(text)\n",
    "    \n",
    "            docsinfo.append(obs)\n",
    "\n",
    "    #create dataframe from dictionary, make date column date type, and store in csv\n",
    "        docsdf = pd.DataFrame(docsinfo)\n",
    "        docsdf['date'] = pd.to_datetime(docsdf['date'])\n",
    "        docsdf.to_csv(\"data/docsdf-{}.csv\".format(count), encoding = 'utf-8') \n",
    "\n",
    "    print(count, pcount) \n",
    "    count += 1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content_kicker': 'Sports Briefing', 'sub': 'TENNIS ;'}\n"
     ]
    }
   ],
   "source": [
    "#testing when key error occurs\n",
    "for d in docs:\n",
    "    if d['headline'].get('main') is None:\n",
    "        print(d['headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No JSON object could be decoded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0a383336cc88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0murl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=Health&page=1&begin_date=19810711&end_date=19810720&api-key=5cdab36b05348a4da2e74046dfb16a03:17:73541790\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'response'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'meta'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hits'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpagedoc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'response'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'docs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\requests\\models.pyc\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    803\u001b[0m                     \u001b[1;31m# used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\json\\__init__.pyc\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    336\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\json\\decoder.pyc\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \"\"\"\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\json\\decoder.pyc\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No JSON object could be decoded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No JSON object could be decoded"
     ]
    }
   ],
   "source": [
    "##To test for page results\n",
    "\n",
    "docs = []\n",
    "url1 = \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=Health&page=1&begin_date=19810711&end_date=19810720&api-key=5cdab36b05348a4da2e74046dfb16a03:17:73541790\" \n",
    "lpage = requests.get(url1).json()['response']['meta']['hits']\n",
    "\n",
    "pagedoc1 = requests.get(url1).json()['response']['docs']\n",
    "for j in range(0,len(pagedocs)):\n",
    "    docs.append(pagedoc1[j])\n",
    "\n",
    "for i in range(2, int(lpage/10 + 2)): \n",
    "    url = \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=Health&page=%d&begin_date=19810711&end_date=19810720&api-key=5cdab36b05348a4da2e74046dfb16a03:17:73541790\" % i\n",
    "    pagedocs = requests.get(url).json()['response']['docs']\n",
    "    time.sleep(1)\n",
    "    print(i)\n",
    "    \n",
    "    #append each separate dictionary from a page to docs\n",
    "    for j in range(0,len(pagedocs)):\n",
    "        docs.append(pagedocs[j])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "print lpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abstract              object\n",
       "date          datetime64[ns]\n",
       "doctype               object\n",
       "headline              object\n",
       "id                    object\n",
       "news_desk             object\n",
       "paragraph             object\n",
       "section               object\n",
       "subsection            object\n",
       "text                  object\n",
       "type                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open(\"nytdocs100.json\") as json_file:\n",
    "#    docs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make date column a date type\n",
    "\n",
    "http://stackoverflow.com/questions/9504356/convert-string-into-date-type-on-python\n",
    "\n",
    "http://stackoverflow.com/questions/16852911/how-do-i-convert-dates-in-a-pandas-data-frame-to-a-date-data-type  ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docsdf.to_csv(\"docsdf100-2.csv\")  #, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>date</th>\n",
       "      <th>doctype</th>\n",
       "      <th>headline</th>\n",
       "      <th>id</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>section</th>\n",
       "      <th>subsection</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-03</td>\n",
       "      <td>article</td>\n",
       "      <td>Know Your Risks, but Meat Still Isnt the Enemy</td>\n",
       "      <td>56374e0a798810408f299696</td>\n",
       "      <td>Upshot</td>\n",
       "      <td>The link between processed meat and cancer is ...</td>\n",
       "      <td>The Upshot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Know Your Risks, but Meat Still Isnt the Enem...</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Study in journal The Lancet concludes Chinese ...</td>\n",
       "      <td>2015-10-13</td>\n",
       "      <td>article</td>\n",
       "      <td>Study Shows Spread of Cigarettes in China</td>\n",
       "      <td>561bc3a67988101d11e0da9e</td>\n",
       "      <td>Science</td>\n",
       "      <td>Chinese men smoke one-third of all the worlds...</td>\n",
       "      <td>Health</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Study Shows Spread of Cigarettes in China Chin...</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Food and Drug Administration approves Narcan n...</td>\n",
       "      <td>2015-11-19</td>\n",
       "      <td>article</td>\n",
       "      <td>F.D.A. Approves a Nasal Spray to Combat Opioid...</td>\n",
       "      <td>564d433579881039a958bb07</td>\n",
       "      <td>National</td>\n",
       "      <td>A nasal spray designed to reverse opioid overd...</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F.D.A. Approves a Nasal Spray to Combat Opioid...</td>\n",
       "      <td>Brief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-17</td>\n",
       "      <td>article</td>\n",
       "      <td>How to Decrease Prices for an Expensive Class ...</td>\n",
       "      <td>5649c243798810095961385d</td>\n",
       "      <td>Upshot</td>\n",
       "      <td>Two professors suggest requiring biologic manu...</td>\n",
       "      <td>The Upshot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How to Decrease Prices for an Expensive Class ...</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-10-07</td>\n",
       "      <td>article</td>\n",
       "      <td>Ragout With Farfalle Gets a Touch of Green</td>\n",
       "      <td>56143f92798810321b0fac91</td>\n",
       "      <td>Dining</td>\n",
       "      <td>The sweet taste and texture of broccoli leaves...</td>\n",
       "      <td>Food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ragout With Farfalle Gets a Touch of Green The...</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           abstract        date  doctype                                           headline                        id news_desk                                          paragraph     section subsection                                               text   type\n",
       "0           0                                                NaN  2015-11-03  article    Know Your Risks, but Meat Still Isnt the Enemy  56374e0a798810408f299696    Upshot  The link between processed meat and cancer is ...  The Upshot        NaN  Know Your Risks, but Meat Still Isnt the Enem...   News\n",
       "1           1  Study in journal The Lancet concludes Chinese ...  2015-10-13  article          Study Shows Spread of Cigarettes in China  561bc3a67988101d11e0da9e   Science  Chinese men smoke one-third of all the worlds...      Health        NaN  Study Shows Spread of Cigarettes in China Chin...   News\n",
       "2           2  Food and Drug Administration approves Narcan n...  2015-11-19  article  F.D.A. Approves a Nasal Spray to Combat Opioid...  564d433579881039a958bb07  National  A nasal spray designed to reverse opioid overd...        U.S.        NaN  F.D.A. Approves a Nasal Spray to Combat Opioid...  Brief\n",
       "3           3                                                NaN  2015-11-17  article  How to Decrease Prices for an Expensive Class ...  5649c243798810095961385d    Upshot  Two professors suggest requiring biologic manu...  The Upshot        NaN  How to Decrease Prices for an Expensive Class ...   News\n",
       "4           4                                                NaN  2015-10-07  article         Ragout With Farfalle Gets a Touch of Green  56143f92798810321b0fac91    Dining  The sweet taste and texture of broccoli leaves...        Food        NaN  Ragout With Farfalle Gets a Touch of Green The...   News"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsdf = pd.read_csv(\"docsdf100-2.csv\", encoding = \"ISO-8859-1\")\n",
    "docsdf.head()\n",
    "\n",
    "#http://stackoverflow.com/questions/18171739/unicodedecodeerror-win-reading-csv-file-in-pandas-with-python\n",
    "#http://stackoverflow.com/questions/24616678/unicodedecodeerror-in-python-when-reading-a-file-how-to-ignore-the-error-and-ju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#solving keyerror issue for headline\n",
    "\n",
    "ex = {'main': 'words', 'kicker': 'stuff'}\n",
    "if ex.get('name') is None:\n",
    "    print('ok')\n",
    "\n",
    "#http://stackoverflow.com/questions/6130768/return-none-if-dictionary-key-is-not-available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
